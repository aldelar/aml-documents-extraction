{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.telemetry import set_diagnostics_collection\n",
    "set_diagnostics_collection(send_diagnostics=True)\n",
    "\n",
    "from azureml.core.workspace import Workspace\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name,\n",
    "      'Azure region: ' + ws.location,\n",
    "      'Subscription id: ' + ws.subscription_id,\n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cpu_cluster_name = \"cpu-8x-f8s\"\n",
    "cpu_compute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "print(f\"CPU Compute target: {cpu_compute_target.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment,Datastore\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.pipeline.core import Pipeline,PipelineData\n",
    "from azureml.pipeline.core.pipeline_output_dataset import PipelineOutputFileDataset\n",
    "from azureml.pipeline.steps import ParallelRunStep, ParallelRunConfig\n",
    "\n",
    "# Environment Definitions\n",
    "cpu_env = Environment.from_conda_specification(name = \"ubuntu\",file_path = \"./conda-cpu.yml\")\n",
    "cpu_env.docker.enabled = True\n",
    "cpu_env.docker.base_image = \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\"\n",
    "\n",
    "# control parallelism\n",
    "cpu_node_count=1\n",
    "cpu_process_count_per_node=8\n",
    "\n",
    "#\n",
    "datastore_name = 'data'\n",
    "datastore = Datastore.get(ws, datastore_name)\n",
    "\n",
    "# pdf input\n",
    "pdf_ni = Dataset.get_by_name(ws, name='1_raw').as_named_input(\"pdf\")\n",
    "\n",
    "# for intermediate data files\n",
    "png_pd = PipelineOutputFileDataset(PipelineData(name=\"png\",datastore=datastore))\n",
    "documents_pd = PipelineOutputFileDataset(PipelineData(name=\"classification\",datastore=datastore))\n",
    "metadata_pd = PipelineOutputFileDataset(PipelineData(name=\"metadata\",datastore=datastore))\n",
    "\n",
    "# convert to png\n",
    "pdf_to_png_config = ParallelRunConfig(\n",
    "    source_directory='1_pdf_to_png',\n",
    "    entry_script=\"pdf_to_png.py\",\n",
    "    mini_batch_size=\"5\", \n",
    "    error_threshold=1,\n",
    "    output_action=\"append_row\",\n",
    "    append_row_file_name=\"1_pdf_to_png.csv\",\n",
    "    environment=cpu_env,\n",
    "    compute_target=cpu_compute_target,\n",
    "    node_count=cpu_node_count,\n",
    "    process_count_per_node=cpu_process_count_per_node\n",
    ")\n",
    "pdf_to_png_step = ParallelRunStep(\n",
    "    name=\"pdf-to-png\",\n",
    "    parallel_run_config=pdf_to_png_config,\n",
    "    arguments=[\"--png-folder\", png_pd],\n",
    "    inputs=[pdf_ni],\n",
    "    output=png_pd,\n",
    "    allow_reuse=True\n",
    ")\n",
    "\n",
    "# classify document\n",
    "document_classification_config = ParallelRunConfig(\n",
    "    source_directory='2_document_classification',\n",
    "    entry_script=\"document_classification.py\",\n",
    "    mini_batch_size=\"5\", \n",
    "    error_threshold=1,\n",
    "    output_action=\"append_row\",\n",
    "    append_row_file_name=\"2_document_classification.csv\",\n",
    "    environment=cpu_env,\n",
    "    compute_target=cpu_compute_target,\n",
    "    node_count=cpu_node_count,\n",
    "    process_count_per_node=cpu_process_count_per_node\n",
    ")\n",
    "document_classification_step = ParallelRunStep(\n",
    "    name=\"document-classification\",\n",
    "    parallel_run_config=document_classification_config,\n",
    "    arguments=[\"--documents-folder\", documents_pd],\n",
    "    inputs=[png_pd],\n",
    "    output=documents_pd,\n",
    "    allow_reuse=True\n",
    ")\n",
    "\n",
    "# extract metadata\n",
    "form_metadata_extraction_config = ParallelRunConfig(\n",
    "    source_directory='3_form_metadata_extraction',\n",
    "    entry_script=\"form_metadata_extraction.py\",\n",
    "    mini_batch_size=\"5\", \n",
    "    error_threshold=1,\n",
    "    output_action=\"append_row\",\n",
    "    append_row_file_name=\"3_form_metadata_extraction.csv\",\n",
    "    environment=cpu_env,\n",
    "    compute_target=cpu_compute_target,\n",
    "    node_count=cpu_node_count,\n",
    "    process_count_per_node=cpu_process_count_per_node\n",
    ")\n",
    "form_metadata_extraction_step = ParallelRunStep(\n",
    "    name=\"form-metadata-extraction\",\n",
    "    parallel_run_config=form_metadata_extraction_config,\n",
    "    arguments=[\"--png-folder\", png_pd,\n",
    "              \"--metadata-folder\", metadata_pd],\n",
    "    inputs=[documents_pd],\n",
    "    output=metadata_pd,\n",
    "    allow_reuse=True\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[form_metadata_extraction_step])\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'pdf-to-cosmosDB'\n",
    "experiment = Experiment(ws, name=experiment_name)\n",
    "run = experiment.submit(pipeline,tags={'cpu_nodes': str(cpu_node_count)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-static",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-economics",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
